"""
LangGraph ToolNode ã¨ å®Ÿéš›ã®MCP ã®çµ±åˆã‚µãƒ³ãƒ—ãƒ«ï¼ˆéåŒæœŸå‡¦ç†ç‰ˆï¼‰

ã“ã®ã‚µãƒ³ãƒ—ãƒ«ã§ã¯ã€Streamable HTTPçµŒç”±ã§ãƒ­ãƒ¼ã‚«ãƒ«MCPã‚µãƒ¼ãƒãƒ¼ (mcp_server.py) ã«æ¥ç¶šã—ã€
LangGraphã®ToolNodeã§ä½¿ç”¨ã—ã¾ã™ã€‚

é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ:
1. MCPã‚µãƒ¼ãƒãƒ¼ã‚’Streamable HTTPã§èµ·å‹•
2. MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§éåŒæœŸé€šä¿¡
3. LangGraphã®ToolNodeã§ä½¿ç”¨

å®Ÿè¡Œå‰ã®æº–å‚™:
1. åˆ¥ã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§MCPã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•: python mcp_server.py
2. ã‚µãƒ¼ãƒãƒ¼ãŒ http://localhost:8000/mcp ã§èµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
"""

import asyncio
from contextlib import asynccontextmanager
from typing import Any

from langchain_aws import ChatBedrockConverse
from langchain_core.messages import HumanMessage
from langchain_core.tools import StructuredTool
from langgraph.graph import START, MessagesState, StateGraph
from langgraph.graph.state import CompiledStateGraph
from langgraph.prebuilt import ToolNode, tools_condition
from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client
from mcp.types import TextContent

from utils import print_messages

# =============================================================================
# MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®š
# =============================================================================


class MCPClientManager:
    """MCPã‚µãƒ¼ãƒãƒ¼ã¨ã®æ¥ç¶šã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, base_url: str = "http://localhost:8000/mcp"):
        self.base_url = base_url
        self.session: ClientSession | None = None

    @asynccontextmanager
    async def connect(self):
        """MCPã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šï¼ˆStreamable HTTPï¼‰"""
        async with streamablehttp_client(self.base_url) as (read, write, _):
            async with ClientSession(read, write) as session:
                await session.initialize()
                self.session = session
                yield session

    async def call_tool(self, tool_name: str, arguments: dict[str, Any]) -> str:
        """MCPãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™"""
        if not self.session:
            raise RuntimeError("MCP session not initialized")

        result = await self.session.call_tool(tool_name, arguments)

        # çµæœã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        if result.content:
            return "\n".join(
                item.text if isinstance(item, TextContent) else str(item)
                for item in result.content
            )
        return ""


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªMCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
mcp_manager = MCPClientManager()


# =============================================================================
# MCPãƒ„ãƒ¼ãƒ«ã‚’LangChainãƒ„ãƒ¼ãƒ«ã«ãƒ©ãƒƒãƒ—
# =============================================================================


async def calculate_mcp(operation: str, a: float, b: float) -> str:
    """
    ãƒ­ãƒ¼ã‚«ãƒ«MCPã‚µãƒ¼ãƒãƒ¼ã®è¨ˆç®—æ©Ÿãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨

    ã“ã‚Œã¯æœ¬ç‰©ã®MCPãƒ„ãƒ¼ãƒ«ã§ã™ï¼

    Args:
        operation: å®Ÿè¡Œã™ã‚‹æ¼”ç®— (add, subtract, multiply, divide)
        a: æœ€åˆã®æ•°å€¤
        b: 2ç•ªç›®ã®æ•°å€¤
    """
    print(f"  [MCP] Calculating: {a} {operation} {b}...")
    result = await mcp_manager.call_tool(
        "calculate", {"operation": operation, "a": a, "b": b}
    )
    return result


# =============================================================================
# LangChainãƒ„ãƒ¼ãƒ«ã¸ã®å¤‰æ›
# =============================================================================

calculate_tool = StructuredTool.from_function(
    coroutine=calculate_mcp,
    name="calculate",
    description="2ã¤ã®æ•°å€¤ã§å››å‰‡æ¼”ç®—ï¼ˆåŠ ç®—ã€æ¸›ç®—ã€ä¹—ç®—ã€é™¤ç®—ï¼‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚",
)

tools = [calculate_tool]

# =============================================================================
# LangGraphã®è¨­å®š
# =============================================================================

llm = ChatBedrockConverse(
    model="global.anthropic.claude-sonnet-4-5-20250929-v1:0",
    region_name="us-east-1",
)

llm_with_tools = llm.bind_tools(tools)


async def call_model(state: MessagesState) -> dict:
    """éåŒæœŸã§LLMã‚’å‘¼ã³å‡ºã™"""
    messages = state["messages"]
    print("\n LLMå‘¼ã³å‡ºã—ä¸­...")
    response = await llm_with_tools.ainvoke(messages)
    return {"messages": [response]}


def create_graph() -> CompiledStateGraph:
    """ToolNodeã‚’å«ã‚€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
    workflow = StateGraph(MessagesState)

    workflow.add_node("agent", call_model)
    workflow.add_node("tools", ToolNode(tools))

    workflow.add_edge(START, "agent")
    workflow.add_conditional_edges("agent", tools_condition)
    workflow.add_edge("tools", "agent")

    return workflow.compile()


# =============================================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =============================================================================


async def main() -> None:
    """éåŒæœŸã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""

    print("=" * 70)
    print("LangGraph + ãƒ­ãƒ¼ã‚«ãƒ«MCPã‚µãƒ¼ãƒãƒ¼ï¼ˆStreamable HTTPï¼‰çµ±åˆãƒ‡ãƒ¢")
    print("=" * 70)
    print("\nğŸ“ ã“ã®ãƒ‡ãƒ¢ã§ã¯:")
    print("  - ãƒ­ãƒ¼ã‚«ãƒ«MCPã‚µãƒ¼ãƒãƒ¼ (mcp_server.py) ã«æ¥ç¶š")
    print("  - Streamable HTTP ã§é€šä¿¡")
    print("  - LangGraphã®ToolNodeã§ä½¿ç”¨")
    print("  - éåŒæœŸå‡¦ç†ã§åŠ¹ç‡çš„ã«å®Ÿè¡Œ")
    print("=" * 70)

    # MCPã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶š
    print("\nğŸ”Œ HTTP MCPã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šä¸­ (http://localhost:8000/mcp)...")
    try:
        async with mcp_manager.connect() as session:
            print("âœ… MCPã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã—ã¾ã—ãŸ")

            # åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ã‚’ç¢ºèª
            tools_list = await session.list_tools()
            print(f"\nğŸ“‹ åˆ©ç”¨å¯èƒ½ãªMCPãƒ„ãƒ¼ãƒ«: {len(tools_list.tools)}å€‹")
            for tool in tools_list.tools:
                print(f"  - {tool.name}: {tool.description}")

            print("\n" + "=" * 70)

            # ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
            graph = create_graph()

            # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
            test_queries = [
                "1.5ã¨3ã®åŠ ç®—ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚",
            ]

            for query in test_queries:
                print(f"\n\n{'=' * 70}")
                print(f"Query: {query}")
                print("=" * 70)

                try:
                    result = await graph.ainvoke(
                        {"messages": [HumanMessage(content=query)]}
                    )

                    print("\n" + "=" * 70)
                    print("å®Ÿè¡Œçµæœ:")
                    print("=" * 70)
                    print_messages(result)

                except Exception as e:
                    print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    import traceback

                    traceback.print_exc()

    except Exception as e:
        print(f"\nâŒ MCPã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        print("\nä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
        print("  1. MCPã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹: python mcp_server.py")
        print("  2. ã‚µãƒ¼ãƒãƒ¼ãŒ http://localhost:8000/mcp ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã‹")
        import traceback

        traceback.print_exc()
        return

    print("\n" + "=" * 70)
    print("âœ… ãƒ‡ãƒ¢å®Œäº†")
    print("=" * 70)


if __name__ == "__main__":
    asyncio.run(main())
